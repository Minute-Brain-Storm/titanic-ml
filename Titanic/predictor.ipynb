{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, multiprocessing, csv, copy\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "INPUT_PATH = os.path.join(\".\", \"CSVs\", \"inputs\")\n",
    "OUTPUT_PATH = os.path.join(\".\", \"CSVs\", \"outputs\")\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from the CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(INPUT_PATH, \"test.csv\"))\n",
    "train = pd.read_csv(os.path.join(INPUT_PATH, \"train.csv\"))\n",
    "\n",
    "train_X = train.drop(axis = 1, columns = \"Survived\")\n",
    "train_y = train[\"Survived\"]\n",
    "marker = len(train_X)\n",
    "\n",
    "dataset = pd.concat([train_X, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for outputing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscores: (accuracy)\\n    SGD classifier 0.73205\\n    Random Forest 0.76555\\n    SVC 0.78708\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_out(vals, filename):\n",
    "    file_path = os.path.join(OUTPUT_PATH, filename) + \".csv\"\n",
    "\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        # creating a csv writer object  \n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        # writing the fields  \n",
    "        csvwriter.writerow([\"PassengerId\",\"Survived\"])\n",
    "        for num in range(418):\n",
    "            csvwriter.writerow([num+892, int(vals[num])])\n",
    "\n",
    "'''\n",
    "scores: (accuracy)\n",
    "    SGD classifier 0.73205\n",
    "    Random Forest 0.76555\n",
    "    SVC 0.78708\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs):\n",
    "        self.attribs = attribs\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns = self.attribs)\n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        r_val = self.transform(X)\n",
    "        self.cols = r_val.columns\n",
    "        return r_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeEstimator(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        return self\n",
    "    def fit(self, X, y=None):\n",
    "        valid = X.dropna(subset=['Age'], inplace = False)\n",
    "        missing = X[X.isnull()['Age']]\n",
    "        valid_X = valid.drop(columns=['Age'], inplace=False)\n",
    "\n",
    "        self.regr = Lasso(alpha = 0.1).fit(valid_X, valid[\"Age\"])\n",
    "        X.loc[X.isnull()['Age'], 'Age'] = self.regr.predict(missing.drop(columns = ['Age']))\n",
    "        \n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filler(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        return self\n",
    "    def fit(self, X, y=None):\n",
    "        for x in X:\n",
    "            if (x != 'Age') & (x != 'Sex') & (x != 'Embarked'):\n",
    "                median = X[x].median()\n",
    "                X[x].fillna(median, inplace=True)\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame({'class_f':[], 'class_s':[], 'class_t':[],\n",
    "                          'emb_s':[], 'emb_c':[], 'emb_q':[],\n",
    "                          'officer':[], 'royalty':[], 'mr':[], 'mrs':[], 'miss':[], 'master':[]})\n",
    "        class_dict = {1:'class_f', 2:'class_s', 3:'class_t'}\n",
    "        emb_dict = {'S':'emb_s', 'C':'emb_c', 'Q':'emb_q'}\n",
    "        title_dict = {\n",
    "            'capt':'officer',\n",
    "            'col':'officer',\n",
    "            'major':'officer',\n",
    "            'jonkheer':'royalty',\n",
    "            'don':'royalty',\n",
    "            'sir':'royalty',\n",
    "            'dr':'officer',\n",
    "            'rev':'officer',\n",
    "            'the countess':'royalty',\n",
    "            'mme':'mrs',\n",
    "            'mlle':'miss',\n",
    "            'ms':'mrs',\n",
    "            'mr':'mr',\n",
    "            'mrs':'mrs',\n",
    "            'miss':'miss',\n",
    "            'master':'master',\n",
    "            'lady':'royalty'\n",
    "        } #dict taken from https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n",
    "        \n",
    "        for i in X.index:\n",
    "            class_key = X.at[i, 'Pclass']\n",
    "            emb_key = X.at[i, 'Embarked']\n",
    "            \n",
    "            if class_key in class_dict:\n",
    "                df.at[i, class_dict[class_key]] = 1\n",
    "            if emb_key in emb_dict:\n",
    "                df.at[i, emb_dict[emb_key]] = 1\n",
    "            \n",
    "            name = X.at[i, 'Name'].lower()\n",
    "            for key in title_dict.keys():\n",
    "                if name.find(key) > -1:\n",
    "                    df.at[i, title_dict[key]] = 1\n",
    "                    break\n",
    "        \n",
    "        X = X.mask(X == 'male', 0)\n",
    "        X = X.mask(X == 'female', 1)\n",
    "                \n",
    "        df.fillna(0, inplace = True)\n",
    "        return pd.concat((df, X.drop(columns = ['Pclass', 'Embarked', 'Name'])), join = 'inner', axis = 1)\n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamilyCombiner(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        fam = []\n",
    "        for i in X.index:\n",
    "            num = X.at[i, 'SibSp'] +  X.at[i, 'Parch']\n",
    "            fam.append(num)\n",
    "        X['family_size'] = fam\n",
    "        X.drop(columns = ['SibSp', 'Parch'], inplace = True)\n",
    "        return X\n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "drop_attribs = ['Cabin', 'PassengerId', 'Ticket'] #need to be dropped before the age estimator, aren't good estimators\n",
    "drop_attribs2 = ['royalty', 'mrs', 'master', 'officer', 'emb_s', 'emb_c', 'emb_q'] #according to a random forest classifier, these are the least important features\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', Encoder()),\n",
    "    ('family_comb', FamilyCombiner()),\n",
    "    ('dropper', AttributeDropper(drop_attribs)),\n",
    "    ('filler', Filler()),\n",
    "    ('age_est', AgeEstimator()),\n",
    "    ('addtl_dropper', AttributeDropper(drop_attribs2)), #comment out this line and rerun the cell with the mathplot to see the importances of these features, also uncomment the line commented out in the cell below this \n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = pipeline.fit_transform(dataset)\n",
    "cols = pipeline.named_steps['addtl_dropper'].cols #comment here\n",
    "#cols = pipeline.named_steps['dropper'].cols #uncomment here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the prepared data back into two seperate ndarrays, the test and training vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_prep = data_prep[:marker]\n",
    "test_prep = data_prep[marker:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a variety of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regressor\n",
    "\n",
    "param_grid = [{\n",
    "    'n_estimators': [130, 150, 160, 170, 180, 200],\n",
    "    'max_depth': [6, 7, 8, 9, 10],\n",
    "}]\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "grid_search = GridSearchCV(forest_clf, param_grid, cv=5,\n",
    "                           scoring='f1',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(train_X_prep, train_y)\n",
    "random_forest = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "forest_vals = random_forest.predict(test_prep)\n",
    "write_out(forest_vals, \"Random_Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 9 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vals = random_forest.feature_importances_\n",
    "plt.xticks(rotation=45)\n",
    "plt.bar(range(1, len(vals) + 1), vals, tick_label = cols,\n",
    "        width = 0.5, color = ['blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Classifier\n",
    "svc = SVC(probability = True, kernel = 'rbf')\n",
    "svc.fit(train_X_prep, train_y)\n",
    "svc_vals = svc.predict(test_prep)\n",
    "write_out(svc_vals, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators = [(\"rf\", random_forest), (\"svc\", svc)], voting = \"soft\")\n",
    "voting_clf.fit(train_X_prep, train_y)\n",
    "\n",
    "voting_vals = voting_clf.predict(test_prep)\n",
    "write_out(voting_vals, \"Voting(soft, rf and svc)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGDboosting\n",
    "import xgboost as xgb\n",
    "\n",
    "#params = {\n",
    "#    'max_depth' : [3, 4, 5, 6, 7, 8], 'eta' : [.05, .06, .075, .1], 'gamma': [.3, .35, .4, .45, .5], #grid search to get a feel for the best params\n",
    "#    'objective' : ['binary:hinge']\n",
    "#}\n",
    "\n",
    "\n",
    "#XGBsearch_CV = GridSearchCV(estimator=xgb.XGBRegressor(), param_grid = params,\n",
    "#                            cv=5)\n",
    "\n",
    "#grid_result = XGBsearch_CV.fit(train_X_prep, train_y)\n",
    "#print(grid_result.best_params_)\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X_prep, label=train_y)\n",
    "dtest = xgb.DMatrix(test_prep)\n",
    "\n",
    "\n",
    "param = {'max_depth': 6, 'eta': 0.04, 'objective': 'binary:hinge'}\n",
    "XGB_est = xgb.train(param, dtrain, 100)\n",
    "\n",
    "# make prediction\n",
    "XGB_vals = XGB_est.predict(dtest)\n",
    "write_out(XGB_vals, \"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voting between xgb and svc (need to run XGB again with different objective binary:logistic)\n",
    "#voting_vals2 = []\n",
    "#for i in range(418):\n",
    "#    voting_vals2.append(round((svc_prob[i, 1] + XGB_vals[i]) / 2))\n",
    "#write_out(voting_vals2, \"voting(soft, xgb and svc)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some testing, feel free to ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'here' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ecd59de6b015>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbreakpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhere\u001b[0m \u001b[1;31m#JuypterLabs does not support breakpoints, so this is just a way to stop execution here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'here' is not defined"
     ]
    }
   ],
   "source": [
    "breakpoint = here #JuypterLabs does not support breakpoints, so this is just a way to stop execution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "param_grid = [{'n_estimators': [100, 150, 200, 250, 300], 'max_features': [2, 3, 4, 5, 6, 7, 8]}]\n",
    "class AgeEstimatorTest(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, params = param_grid):\n",
    "        self.params = params\n",
    "    def transform(self, X):\n",
    "        return self\n",
    "    def fit(self, X, y=None):\n",
    "        temp = X.drop(columns=['Age'])\n",
    "        self.regr = Lasso(alpha = 0.1).fit(temp, X[\"Age\"])\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_attribs1 = [\"Name\", \"Cabin\", \"PassengerId\", \"Ticket\"]\n",
    "drop_attribs2 = [\"Name\", \"Cabin\", \"PassengerId\", \"Ticket\", \"Age\"]\n",
    "\n",
    "test_pipeline1 = Pipeline([\n",
    "    ('dropper', AttributeDropper(drop_attribs1)),\n",
    "    ('filler', Filler()),\n",
    "    ('cust_enc', CustEncoder()),\n",
    "    ('family_comb', FamilyCombiner()),\n",
    "    ('hot_encoder', HotEncoder()),\n",
    "    ('age_est', AgeEstimatorTest())\n",
    "])\n",
    "\n",
    "test_pipeline2 = Pipeline([\n",
    "    ('dropper', AttributeDropper(drop_attribs2)),\n",
    "    ('filler', Filler()),\n",
    "    ('cust_enc', CustEncoder()),\n",
    "    ('family_comb', FamilyCombiner()),\n",
    "    ('hot_encoder', HotEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset.dropna(subset = [\"Age\"])\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = test_set.sample(frac = 1, axis = 0)\n",
    "sample = shuffle[:820]\n",
    "s_test = shuffle[820:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prep = test_pipeline1.fit_transform(sample)\n",
    "s_test_prep = test_pipeline2.fit_transform(s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = s_test[\"Age\"]\n",
    "age2 = sample[\"Age\"]\n",
    "\n",
    "age_est = test_pipeline1.named_steps['age_est']\n",
    "\n",
    "score = age_est.regr.score(s_test_prep, age)\n",
    "score2 = age_est.regr.score(sample_prep.drop(columns = \"Age\"), age2)\n",
    "print(score, score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X_prep[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined = np.concatenate((train_X_prep, np.vstack(train_y)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = xgb.DMatrix(train_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
