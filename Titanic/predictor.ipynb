{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, multiprocessing, csv, copy\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "INPUT_PATH = os.path.join(\".\", \"CSVs\", \"inputs\")\n",
    "OUTPUT_PATH = os.path.join(\".\", \"CSVs\", \"outputs\")\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from the CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(INPUT_PATH, \"test.csv\"))\n",
    "train = pd.read_csv(os.path.join(INPUT_PATH, \"train.csv\"))\n",
    "\n",
    "train_X = train.drop(axis = 1, columns = \"Survived\")\n",
    "train_y = train[\"Survived\"]\n",
    "marker = len(train_X)\n",
    "\n",
    "dataset = pd.concat([train_X, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for outputing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscores: (accuracy)\\n    SGD classifier 0.73205\\n    Random Forest 0.76555\\n    SVC 0.78708\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_out(vals, filename):\n",
    "    file_path = os.path.join(OUTPUT_PATH, filename) + \".csv\"\n",
    "\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        # creating a csv writer object  \n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        # writing the fields  \n",
    "        csvwriter.writerow([\"PassengerId\",\"Survived\"])\n",
    "        for num in range(418):\n",
    "            csvwriter.writerow([num+892, int(vals[num])])\n",
    "\n",
    "'''\n",
    "scores: (accuracy)\n",
    "    SGD classifier 0.73205\n",
    "    Random Forest 0.76555\n",
    "    SVC 0.78708\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs):\n",
    "        self.attribs = attribs\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns = self.attribs)\n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        r_val = self.transform(X)\n",
    "        self.cols = r_val.columns\n",
    "        return r_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeEstimator(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        return self\n",
    "    def fit(self, X, y=None):\n",
    "        valid = X.dropna(subset=['Age'], inplace = False)\n",
    "        missing = X[X.isnull()['Age']]\n",
    "        valid_X = valid.drop(columns=['Age'], inplace=False)\n",
    "\n",
    "        self.regr = Lasso(alpha = 0.1).fit(valid_X, valid[\"Age\"])\n",
    "        X.loc[X.isnull()['Age'], 'Age'] = self.regr.predict(missing.drop(columns = ['Age']))\n",
    "        \n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filler(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        return self\n",
    "    def fit(self, X, y=None):\n",
    "        for x in X:\n",
    "            if (x != 'Age') & (x != 'Sex') & (x != 'Embarked'):\n",
    "                median = X[x].median()\n",
    "                X[x].fillna(median, inplace=True)\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame({'class_f':[], 'class_s':[], 'class_t':[],\n",
    "                          'emb_s':[], 'emb_c':[], 'emb_q':[],\n",
    "                          'officer':[], 'royalty':[], 'mr':[], 'mrs':[], 'miss':[], 'master':[]})\n",
    "        class_dict = {1:'class_f', 2:'class_s', 3:'class_t'}\n",
    "        emb_dict = {'S':'emb_s', 'C':'emb_c', 'Q':'emb_q'}\n",
    "        title_dict = {\n",
    "            'capt':'officer',\n",
    "            'col':'officer',\n",
    "            'major':'officer',\n",
    "            'jonkheer':'royalty',\n",
    "            'don':'royalty',\n",
    "            'sir':'royalty',\n",
    "            'dr':'officer',\n",
    "            'rev':'officer',\n",
    "            'the countess':'royalty',\n",
    "            'mme':'mrs',\n",
    "            'mlle':'miss',\n",
    "            'ms':'mrs',\n",
    "            'mr':'mr',\n",
    "            'mrs':'mrs',\n",
    "            'miss':'miss',\n",
    "            'master':'master',\n",
    "            'lady':'royalty'\n",
    "        } #dict taken from https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n",
    "        \n",
    "        for i in X.index:\n",
    "            class_key = X.at[i, 'Pclass']\n",
    "            emb_key = X.at[i, 'Embarked']\n",
    "            \n",
    "            if class_key in class_dict:\n",
    "                df.at[i, class_dict[class_key]] = 1\n",
    "            if emb_key in emb_dict:\n",
    "                df.at[i, emb_dict[emb_key]] = 1\n",
    "            \n",
    "            name = X.at[i, 'Name'].lower()\n",
    "            for key in title_dict.keys():\n",
    "                if name.find(key) > -1:\n",
    "                    df.at[i, title_dict[key]] = 1\n",
    "                    break\n",
    "        \n",
    "        X = X.mask(X == 'male', 0)\n",
    "        X = X.mask(X == 'female', 1)\n",
    "                \n",
    "        df.fillna(0, inplace = True)\n",
    "        return pd.concat((df, X.drop(columns = ['Pclass', 'Embarked', 'Name'])), join = 'inner', axis = 1)\n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamilyCombiner(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        fam = []\n",
    "        for i in X.index:\n",
    "            num = X.at[i, 'SibSp'] +  X.at[i, 'Parch']\n",
    "            fam.append(num)\n",
    "        X['family_size'] = fam\n",
    "        X.drop(columns = ['SibSp', 'Parch'], inplace = True)\n",
    "        return X\n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "drop_attribs = ['Cabin', 'PassengerId', 'Ticket'] #need to be dropped before the age estimator, aren't good estimators\n",
    "drop_attribs2 = ['royalty', 'mrs', 'master', 'officer', 'emb_s', 'emb_c', 'emb_q'] #according to a random forest classifier, these are the least important features\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', Encoder()),\n",
    "    ('family_comb', FamilyCombiner()),\n",
    "    ('dropper', AttributeDropper(drop_attribs)),\n",
    "    ('filler', Filler()),\n",
    "    ('age_est', AgeEstimator()),\n",
    "    ('addtl_dropper', AttributeDropper(drop_attribs2)), #comment out this line and rerun the cell with the mathplot to see the importances of these features, also uncomment the line commented out in the cell below this \n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = pipeline.fit_transform(dataset)\n",
    "cols = pipeline.named_steps['addtl_dropper'].cols #comment here\n",
    "#cols = pipeline.named_steps['dropper'].cols #uncomment here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the prepared data back into two seperate ndarrays, the test and training vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_prep = data_prep[:marker]\n",
    "test_prep = data_prep[marker:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a variety of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor\n",
    "\n",
    "param_grid = [{\n",
    "    'n_estimators': [130, 150, 160, 170, 180, 200],\n",
    "    'max_depth': [6, 7, 8, 9, 10],\n",
    "}]\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "grid_search = GridSearchCV(forest_clf, param_grid, cv=5,\n",
    "                           scoring='f1',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(train_X_prep, train_y)\n",
    "random_forest = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "forest_vals = random_forest.predict(test_prep)\n",
    "write_out(forest_vals, \"Random_Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vals = random_forest.feature_importances_\n",
    "plt.xticks(rotation=45)\n",
    "plt.bar(range(1, len(vals) + 1), vals, tick_label = cols,\n",
    "        width = 0.5, color = ['blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Classifier\n",
    "svc = SVC(probability = True, kernel = 'rbf')\n",
    "svc.fit(train_X_prep, train_y)\n",
    "svc_vals = svc.predict(test_prep)\n",
    "write_out(svc_vals, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators = [(\"rf\", random_forest), (\"svc\", svc)], voting = \"soft\")\n",
    "voting_clf.fit(train_X_prep, train_y)\n",
    "\n",
    "voting_vals = voting_clf.predict(test_prep)\n",
    "write_out(voting_vals, \"Voting(soft, rf and svc)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGDboosting\n",
    "import xgboost as xgb\n",
    "\n",
    "#params = {\n",
    "#    'max_depth' : [3, 4, 5, 6, 7, 8], 'eta' : [.05, .06, .075, .1], 'gamma': [.3, .35, .4, .45, .5], #grid search to get a feel for the best params\n",
    "#    'objective' : ['binary:hinge']\n",
    "#}\n",
    "\n",
    "\n",
    "#XGBsearch_CV = GridSearchCV(estimator=xgb.XGBRegressor(), param_grid = params,\n",
    "#                            cv=5)\n",
    "\n",
    "#grid_result = XGBsearch_CV.fit(train_X_prep, train_y)\n",
    "#print(grid_result.best_params_)\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X_prep, label=train_y)\n",
    "dtest = xgb.DMatrix(test_prep)\n",
    "\n",
    "\n",
    "param = {'max_depth': 6, 'eta': 0.04, 'objective': 'binary:hinge'}\n",
    "XGB_est = xgb.train(param, dtrain, 100)\n",
    "\n",
    "# make prediction\n",
    "XGB_vals = XGB_est.predict(dtest)\n",
    "write_out(XGB_vals, \"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voting between xgb and svc (need to run XGB again with different objective binary:logistic)\n",
    "#voting_vals2 = []\n",
    "#for i in range(418):\n",
    "#    voting_vals2.append(round((svc_prob[i, 1] + XGB_vals[i]) / 2))\n",
    "#write_out(voting_vals2, \"voting(soft, xgb and svc)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some testing, feel free to ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint = here #JuypterLabs does not support breakpoints, so this is just a way to stop execution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "param_grid = [{'n_estimators': [100, 150, 200, 250, 300], 'max_features': [2, 3, 4, 5, 6, 7, 8]}]\n",
    "class AgeEstimatorTest(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, params = param_grid):\n",
    "        self.params = params\n",
    "    def transform(self, X):\n",
    "        return self\n",
    "    def fit(self, X, y=None):\n",
    "        temp = X.drop(columns=['Age'])\n",
    "        self.regr = Lasso(alpha = 0.1).fit(temp, X[\"Age\"])\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_attribs1 = [\"Name\", \"Cabin\", \"PassengerId\", \"Ticket\"]\n",
    "drop_attribs2 = [\"Name\", \"Cabin\", \"PassengerId\", \"Ticket\", \"Age\"]\n",
    "\n",
    "test_pipeline1 = Pipeline([\n",
    "    ('dropper', AttributeDropper(drop_attribs1)),\n",
    "    ('filler', Filler()),\n",
    "    ('cust_enc', CustEncoder()),\n",
    "    ('family_comb', FamilyCombiner()),\n",
    "    ('hot_encoder', HotEncoder()),\n",
    "    ('age_est', AgeEstimatorTest())\n",
    "])\n",
    "\n",
    "test_pipeline2 = Pipeline([\n",
    "    ('dropper', AttributeDropper(drop_attribs2)),\n",
    "    ('filler', Filler()),\n",
    "    ('cust_enc', CustEncoder()),\n",
    "    ('family_comb', FamilyCombiner()),\n",
    "    ('hot_encoder', HotEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset.dropna(subset = [\"Age\"])\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = test_set.sample(frac = 1, axis = 0)\n",
    "sample = shuffle[:820]\n",
    "s_test = shuffle[820:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prep = test_pipeline1.fit_transform(sample)\n",
    "s_test_prep = test_pipeline2.fit_transform(s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = s_test[\"Age\"]\n",
    "age2 = sample[\"Age\"]\n",
    "\n",
    "age_est = test_pipeline1.named_steps['age_est']\n",
    "\n",
    "score = age_est.regr.score(s_test_prep, age)\n",
    "score2 = age_est.regr.score(sample_prep.drop(columns = \"Age\"), age2)\n",
    "print(score, score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X_prep[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined = np.concatenate((train_X_prep, np.vstack(train_y)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = xgb.DMatrix(train_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
