{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, multiprocessing, csv, copy\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "ind_output = True\n",
    "\n",
    "INPUT_PATH = os.path.dirname(\"./CSVs/inputs/\")\n",
    "OUTPUT_PATH = os.path.dirname(\"./CSVs/outputs/\")\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "sgd_vals = pd.read_csv(os.path.join(OUTPUT_PATH, \"Random_Forest.csv\"))\n",
    "rf_vals = pd.read_csv(os.path.join(OUTPUT_PATH, \"SGDClassifier.csv\"))\n",
    "\n",
    "count = 0\n",
    "for i in range(418):\n",
    "    if(sgd_vals.iloc[i, 1] != rf_vals.iloc[i, 1]):\n",
    "        count+=1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from the CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(INPUT_PATH, \"test.csv\"))\n",
    "train = pd.read_csv(os.path.join(INPUT_PATH, \"train.csv\"))\n",
    "\n",
    "train_X = train.drop(axis = 1, columns = \"Survived\")\n",
    "train_y = train[\"Survived\"]\n",
    "marker = len(train_X)\n",
    "\n",
    "dataset = pd.concat([train_X, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(test[\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def countNaN(dataset):\n",
    "    NaNcount = 0\n",
    "    for data in dataset:\n",
    "        if math.isnan(data):\n",
    "            NaNcount = NaNcount + 1\n",
    "    return NaNcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_X))\n",
    "print(countNaN(train_X[\"Age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_attribs = [\"Name\", \"Cabin\", \"PassengerId\", \"Ticket\"]\n",
    "\n",
    "class AttributeDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs = drop_attribs):\n",
    "        self.attribs = attribs\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns = self.attribs, inplace = False)\n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'bootstrap':[True, False], 'n_estimators': [80, 90, 100, 110, 120], 'max_features': [3, 4]}]\n",
    "\n",
    "class AgeEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, params = param_grid):\n",
    "        self.params = params\n",
    "    def transform(self, X):\n",
    "        return self\n",
    "    def fit(self, X, y=None):\n",
    "        X_valid = X.dropna(subset=[\"Age\"], inplace = False)\n",
    "        X_missing = X[X.isnull()[\"Age\"]]\n",
    "        \n",
    "        forest_reg = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "        grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                                   scoring='neg_root_mean_squared_error',\n",
    "                                   return_train_score=True)\n",
    "        \n",
    "        temp = X_valid.drop(columns=[\"Age\"], inplace=False)\n",
    "        grid_search.fit(temp, X_valid[\"Age\"])\n",
    "        forest_regressor = grid_search.best_estimator_\n",
    "        X.loc[X.isnull()[\"Age\"], \"Age\"] = forest_regressor.predict(X_missing.drop(columns = [\"Age\"]))\n",
    "        \n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filler(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        return self\n",
    "    def fit(self, X, y=None):\n",
    "        for x in X:\n",
    "            if x != \"Age\":\n",
    "                median = X[x].median()\n",
    "                X[x].fillna(median, inplace=True)\n",
    "        return X\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "main_cols = list(test.columns)\n",
    "main_cols.remove(\"Sex\")\n",
    "main_cols.remove(\"Embarked\")\n",
    "sex_col = [\"Sex\"]\n",
    "emb_col = [\"Embarked\"]\n",
    "\n",
    "main_pipeline = Pipeline([\n",
    "    (\"dropper\", AttributeDropper()),\n",
    "    (\"filler\", Filler()),\n",
    "    (\"age_estimator\", AgeEstimator())\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"sex\", OrdinalEncoder(categories = [['male', 'female']]), sex_col),\n",
    "    (\"main\", main_pipeline, main_cols),\n",
    "    (\"emb\", OneHotEncoder(categories=[['S', 'C', 'Q']], handle_unknown='ignore'), emb_col)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_fare = dataset[\"Fare\"].median()\n",
    "\n",
    "#train_X[\"Embarked\"].fillna('x', inplace=True)\n",
    "#test[\"Embarked\"].fillna('x', inplace=True)\n",
    "dataset[\"Embarked\"].fillna('x', inplace = True)\n",
    "dataset[\"Fare\"].fillna(med_fare, inplace = True)\n",
    "\n",
    "data_prep = full_pipeline.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  3.        , 23.64243056,  0.        ,  0.        ,\n",
       "        8.4583    ,  0.        ,  0.        ,  1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the prepared data back into two seperate ndarrays, the test and training vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_prep = data_prep[:marker]\n",
    "test_prep = data_prep[marker:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to have a variety of ensemble methods (these methods may require additional data transformation). Listed below are the algorithmns we will use.\n",
    "\n",
    "    Random Forest Classifier\n",
    "    \n",
    "    Support Vector Machine\n",
    "    Gradient Descent Classifier\n",
    "\n",
    "\n",
    "We will use hard voting initially, though it may be worth investigating into the use of a stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'bootstrap':[True, False], 'n_estimators': [80, 90, 100, 110, 120], 'max_features': [3, 4, 5, 6, 7, 8]}\n",
    "]\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "grid_search = GridSearchCV(forest_clf, param_grid, cv=5,\n",
    "                           scoring='f1',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(train_X_prep, train_y)\n",
    "RandomForest = grid_search.best_estimator_\n",
    "\n",
    "forest_vals = RandomForest.predict(test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Individual Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscores: (accuracy)\\n    SGD classifier 0.73205\\n    Random Forest 0.74880, bootstrap false 0.75598\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestFilename = os.path.join(OUTPUT_PATH, \"Random_Forest(with age estimator).csv\")\n",
    "\n",
    "filenames = {}\n",
    "\n",
    "filenames.update({RandomForestFilename: forest_vals})\n",
    "\n",
    "if ind_output == True:\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            # creating a csv writer object  \n",
    "            csvwriter = csv.writer(csvfile)  \n",
    "\n",
    "            # writing the fields  \n",
    "            csvwriter.writerow([\"PassengerId\",\"Survived\"])\n",
    "    \n",
    "            for num in range(418):\n",
    "                csvwriter.writerow([num+892, filenames[filename][num]])\n",
    "\n",
    "'''\n",
    "scores: (accuracy)\n",
    "    SGD classifier 0.73205\n",
    "    Random Forest 0.76555\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "k    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6], 'k': [10, math.nan, 30, 40, math.nan, 60]})\n",
    "\n",
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
